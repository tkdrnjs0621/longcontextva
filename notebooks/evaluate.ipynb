{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00ee8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkdrnjs0621/miniconda3/envs/qwen2a2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b7cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f5c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 125 examples [00:00, 20962.30 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_json('/home/tkdrnjs0621/work/lcva/output_wer.jsonl')\n",
    "hicupid = load_dataset(\"12kimih/HiCUPID\",\"dialogue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted = {}\n",
    "\n",
    "for item in tqdm(hicupid['train']):\n",
    "    user_id = item['user_id']\n",
    "    dialogue_id = item['dialogue_id']\n",
    "    \n",
    "    # Initialize nested structure if not exists\n",
    "    if user_id not in formatted:\n",
    "        formatted[user_id] = {}\n",
    "    if dialogue_id not in formatted[user_id]:\n",
    "        formatted[user_id][dialogue_id] = []\n",
    "    \n",
    "    # Append user and assistant turns as a list\n",
    "    formatted[user_id][dialogue_id].append(item['user'])\n",
    "    formatted[user_id][dialogue_id].append(item['assistant'])\n",
    "\n",
    "formatted_str = {}\n",
    "for uid, dialogs in formatted.items():\n",
    "    formatted_str[uid] = {}\n",
    "    for did, turns in dialogs.items():\n",
    "        lines = []\n",
    "        for i, text in enumerate(turns):\n",
    "            prefix = 'User:' if i % 2 == 0 else 'Assistant:'\n",
    "            lines.append(f'{prefix} {text}')\n",
    "        formatted_str[uid][did] = \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba850bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': '0',\n",
       " 'dialogue_id': '0',\n",
       " 'question': 'What did you say about wearing rainboots in snowy conditions?',\n",
       " 'answer': \"Rainboots can be used in snowy conditions, but they may lack insulation. It's recommended to wear thick, thermal socks for added warmth, or consider insulated rainboots for colder climates.\",\n",
       " 'wer': 0.2,\n",
       " 'asr_result': ' What did you say about wearing rain boots in snowy conditions?',\n",
       " 'txt_i': ' what did you say about wearing rain boots in snowy conditions',\n",
       " 'txt_r': 'what did you say about wearing rainboots in snowy conditions'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d178c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = dataset[0]\n",
    "base_path = '/home/tkdrnjs0621/work/lcva/outputs/dialogue_gt/v1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995fd890",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = row['question']\n",
    "answer = row['answer']\n",
    "uid = row['user_id']\n",
    "did = row['dialogue_id']\n",
    "\n",
    "file_path = base_path + f\"/{uid}_{did}.txt\"\n",
    "try:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        last_line = file.readlines()[-1].strip()\n",
    "        response=last_line\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e12850",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2957690427.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    {\"role\": \"user\", \"content\": \"\"\"\"\"},\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages= [\n",
    "    {\"role\":\"system\",\"content\":\"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"You need to evaluate the performance of a voice assistant in a multi-turn speech interaction scenario. The model receives a speech input from the\n",
    "user, who is asking about the past utterance and generate response.\n",
    "Your task is to assess the model's response in the final turn, based on the user's question and the reference answer.\n",
    "The primary evaluation criterion is how well the model's response includes the key information from the reference answer that is relevant to the user's\n",
    "question. While the model may provide additional information, it must accurately reflect the essential content from the reference answer that pertains to the user's query.\n",
    "\n",
    "### Scoring Criteria (1 to 5 scale):\n",
    "- **1 point**: Fails to include relevant details from the reference answer.\n",
    "- **2 points**: Includes some relevant details but omits key information from the reference answer.\n",
    "- **3 points**: Partially includes relevant details but with omissions or misrepresentations of key points.\n",
    "- **4 points**: Mostly includes the key details from the reference answer, with only minor inaccuracies or omissions.\n",
    "- **5 points**: Fully includes the key information from the reference answer without any omissions or errors.\n",
    "Below are the transcriptions of the user's input, the model's response, and the reference answer:\n",
    "[User Input] {question}\n",
    "[Response] {response}\n",
    "[Reference Answer] {answer}\n",
    "Please output only a single score (1-5) for the conversation without any explanations.\n",
    "\"\"\".strip()},\n",
    "],\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen2a2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
